\label{chapter:influence}

A fundamental problem in research and industry is that of organizing
collections of documents.  In many cases this problem can be reduced
to identifying those documents which have been the most influential.
This is an important and common problem in many fields, including
research in academic fields such as political science, history, and
science.  Influence measurements are used to assess the quality of
academic instruments, such as journals, scientists, and universities;
as such, they can play a role in decisions surrounding publishing and
funding. These measurements are critical for academic researchers:
finding and reading the influential articles of a field is central to
good research practice.

Measurements of influence are also significant in industry, as
regulations such as Sarbanes Oxley require public companies to retain
documents.  E-discovery is another field in which identifying
influential documents is critical.  A recent New York Times article
cited the need for such tools in industry:
\begin{quote}
  \emph{``The economic impact will be huge,'' said Tom Mitchell, chairman
    of the machine learning department at Carnegie Mellon University
    in Pittsburgh. ``We're at the beginning of a 10-year period where
    we're going to transition from computers that can't understand
    language to a point where computers can understand quite a bit
    about language.''} \citep{markoff:2011}.
\end{quote}
The article continues, noting that recent solutions use either
keyword-based search methods or take advantage of metadata such as
citations or links in emails, which can be helpful when available.
Metadata can be a boon for finding the most influential documents in a
collection, but often such metadata is unavailable.

In this chapter, we will describe an approach to identifying
influential articles in a collection without the use of metadata like
citations.  The key assumption of our method is that an influential
article will affect how future articles are written and that this
effect can be detected by examining the way corpus statistics change
over time.  We will take advantage of the tools discussed in the last
chapter by using them to encode this intuition in a model to measure
influence in sequential collections of documents.

\subsection*{Measuring influence with citations}

A traditional method of assessing an article's influence is to count
the citations to it. The impact factor of a journal, for example, is
based on aggregate citation counts~\citep{garfield:2002}.  This is
intuitive: if more people have cited an article, then more people have
read it, and it is likely to have had more impact on its field.
Citation counts are used with other types of documents as well.  The
Pagerank algorithm, for example, uses hyperlinks of web-pages to
identify the most influential Webpages on the Internet, and it was
essential to Google's early success in Web search~\citep{brin:1998}.
There is a large literature on these and other methods for citation
analysis and bibliometrics.  See~\cite{osareh:1996} for a review.

Though citation counts can be powerful, they can be hard to use in
practice.  Some collections, such as news stories, blog posts, or
legal documents, contain articles that were influential on others but
lack explicit citations between them.  Other collections, like OCR
scans of historical scientific literature, do contain citations, but
they are difficult to read in reliable electronic form.  Finally,
citation counts only capture one kind of influence.  All citations
from an article are counted equally in an impact factor, when some
articles of a bibliography might have influenced the authors more than
others.

\subsection*{Using text to measure influence}

One possible solution might be to \emph{predict} citation counts, by
proposing features and training a regression. \cite{tang:2009} and
\cite{lokker:2008} have used methods like this; successful features include
the publishing journal's impact factor, previous citations to last
author, key terms, and number of authors
\citep{tang:2009,lokker:2008}.  Such research has had measured
success: 56\% explained variance \citep{lokker:2008}, and 91.5\%
prediction accuracy \citep{ibanez:2009}.

However, we seek a model that is applicable to collections for which
the notion of citation may not exist.  Therefore, predicting citations
is an explicit non-goal.  Further, work toward predicting citations
uses specialized classifiers and restrictive features for narrow
application domains; \cite{lokker:2008} even note that their results
``may not be readily transferable to... basic science articles or
journals''. They further noted that earlier work in their field of
predicting citations to medical journals had only achieved 14\% to
20\% explained variance \citep{lokker:2008}.

%\subsubsection*{Using text to measure influence}

%interdisciplinary journal such as \textit{Nature} might have influence
%on Neuroscience without having influence on Genomics.  In our model,
%both the topics and influential articles are inferred.

In this chapter we will use a text-based approach to measure influence.
We will base our assumptions on a topic model which allows topics to drift
over time in a corpus~\citep{blei:2006}. Though our algorithm aims to
capture something different from citation, we will validate the
inferred influence measurements by comparing them to citation counts.

We begin with a discussion of previous work aimed at modeling
influential documents.  We then describe the Document Influence Model
(DIM), our unsupervised model for determining the influence of a
document using the changes in language used by documents over time.
We follow this with experiments to compare this model with citation
counts on three well-known scientific corpora and a collection of
legal opinions.  We will also provide the reader with an intuition for
the model with several real-world examples. With only the language of
the articles as input, our algorithm produces a meaningful measure of
each document's influence in the corpus.
