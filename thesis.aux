\relax 
\@writefile{toc}{\contentsline {section}{Abstract}{iii}}
\@writefile{toc}{\contentsline {section}{Acknowledgements}{iv}}
\citation{lazer:2009}
\citation{googleblog:2008}
\citation{changrtl:2009}
\citation{pearl:1985}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introduction}{2}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {1.1}Social science data analysis}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {1.2}Organization}{3}}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Preliminary material: quantitative methods}{5}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{chapter:introductory_material}{{2}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}Standards and naming conventions}{5}}
\@writefile{lot}{\contentsline {table}{\numberline {2.1}{\ignorespaces Notation used throughout this thesis.}}{6}}
\newlabel{section:pipeline}{{2.1}{6}}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}Latent-variable models for prediction and exploratoration}{6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Data analysis pipepline}{6}}
\newlabel{section:data_analysis_pipeline}{{2.2.1}{6}}
\citation{box:1980}
\citation{gelman:1996}
\citation{tufte:2001}
\citation{wilkinson:2005}
\citation{chaney:2012}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces A data analysis pipeline. In this work, we discuss elements of defining modeling assumptions, model implementation, and model revision. We will focus on applications which use text data.}}{8}}
\newlabel{figure:data_analysis_pipeline}{{2.1}{8}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}Latent-variable models}{8}}
\newlabel{lvm:matching}{{2}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Undirected graphical models for summarizing distributional assumptions}{9}}
\citation{bishop:2006}
\citation{bishop:2006}
\citation{grimmer:submitted}
\citation{blei:2003}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Left: graphical model for a unigram language model. Documents $1, \ldots  , D$ are treated as \emph  {bags of words}, or collections of words $w_n$. Right: graphical model for Latent Dirichlet Allocation. Circles are random variables, arrows connote dependency, and plates represent replication. The circles represent observed random variables (words in this case).}}{11}}
\newlabel{fig:bagofwords_lda_gm}{{2.2}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Text as a medium for social science analysis}{11}}
\newlabel{section:text_intro}{{2.2.4}{11}}
\@writefile{toc}{\contentsline {subsubsection}{Latent Dirichlet Allocation}{12}}
\citation{salakhutdinov:2008a}
\citation{clinton:2004}
\citation{martin:2002}
\citation{poole:1991}
\citation{enelow:1984}
\citation{albert:1992}
\@writefile{lot}{\contentsline {table}{\numberline {2.2}{\ignorespaces Example topics from Latent Dirichlet Allocation fit to sentences from the the textbook \emph  {Biology} by Campbell and Reece. This is a small subset of the 1000 topics. These topics were graciously provided by Ricky Wong.}}{13}}
\newlabel{table:example_lda_topics}{{2.2}{13}}
\@writefile{toc}{\contentsline {subsubsection}{Inference}{13}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.5}Ideal point models and matrix factorization}{13}}
\citation{wang:2011}
\citation{salakhutdinov:2008a}
\citation{poole:1985}
\citation{poole:1991}
\citation{clinton:2004}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces Probabilistic matrix factorization. We observe interactions $V_{ud}$ between users represented by $X_u$ and items represented by $A_d, B_d$.}}{14}}
\newlabel{figure:irt_gm}{{2.3}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.6}Hidden Markov Models and Kalman Filters}{14}}
\citation{bishop:2006}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces A hidden Markov model. Observations $Y_1, \ldots  , Y_T$ are observed at discrete times $t=1, \ldots  , T$, and are conditionally independent given the hidden states $X_1, \ldots  , X_T$.}}{15}}
\newlabel{figure:hmm_gm}{{2.4}{15}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Posterior inference and model evaluation}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}MAP estimation}{15}}
\citation{jordan:2003}
\citation{jordan:1999}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}MCMC}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Variational inference}{16}}
\newlabel{section:variational_inference}{{2.3.3}{16}}
\newlabel{equation:variational_objective}{{2.10}{16}}
\citation{jordan:1999}
\citation{gerrish:2011}
\citation{bishop:2006}
\citation{blei:2003}
\citation{bickel:2007}
\citation{braun:2007}
\newlabel{figure:variational_inference}{{2.3.3}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Illustration of variational inference. Practitioners define a variational family (shaded yellow region) and find the member of that family $q_{\mathaccentV {hat}05E\eta }(x)$ which is closest (by KL divergence) to the true posterior.}}{17}}
\newlabel{equation:traditional_variational_objective}{{2.11}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Model evaluation}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Likelihood of training data $Y_1, \ldots  , Y_{N_{\unhbox \voidb@x \hbox {obs}}}$}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Likelihood of heldout observations $Y_1, \ldots  , Y_{N_{\unhbox \voidb@x \hbox {heldout}}}$}{18}}
\@writefile{toc}{\contentsline {subsubsection}{Relationship with external data}{19}}
\@writefile{toc}{\contentsline {section}{\numberline {2.4}Using these tools to understand influence and decisionmaking}{19}}
\citation{garfield:2002}
\citation{brin:1998}
\citation{osareh:1996}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}A model of influence in text documents}{20}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{blei:2006}
\citation{tang:2009}
\citation{lokker:2008}
\citation{tang:2009}
\citation{lokker:2008}
\citation{lokker:2008}
\citation{ibanez:2009}
\citation{lokker:2008}
\citation{lokker:2008}
\citation{nallapati:2008}
\citation{chang:2009}
\citation{dietz:2007}
\citation{Cohn01themissing}
\citation{mcnee:2002}
\citation{ibanez:2009}
\citation{qazvinian:2008}
\citation{mann:2006}
\citation{borner:2003}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}The Document Influence Model}{22}}
\newlabel{section:model}{{3.1}{22}}
\citation{blei:2006}
\citation{blei:2003}
\citation{deerwester:1990}
\citation{hofmann:1999}
\citation{blei:2006}
\newlabel{fig:doc_influence_model}{{3.1}{23}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.1}{\ignorespaces  The Dynamic Topic Model (a) and the the Document Influence Model (b).}}{23}}
\newlabel{fig:gm}{{3.1}{23}}
\@writefile{toc}{\contentsline {paragraph}{Drifting Topics.}{23}}
\newlabel{eq:softmax}{{3.1}{23}}
\newlabel{eq:logistic-normal}{{3.2}{23}}
\@writefile{toc}{\contentsline {paragraph}{Documents generated at time $t$.}{23}}
\newlabel{eq:logistic-normal-influence}{{3.3}{24}}
\citation{blei:2003}
\citation{porter:2005}
\citation{leskovec:2009}
\citation{shaparenko:2007}
\citation{shaparenko:2007}
\@writefile{toc}{\contentsline {paragraph}{Multiple topics.}{25}}
\newlabel{eq:logistic-normal-influence-topics}{{3.4}{25}}
\citation{blei:2003}
\citation{blei:2006}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Inference and parameter estimation}{26}}
\newlabel{section:inference}{{3.2}{26}}
\citation{blei:2006}
\citation{blei:2006}
\citation{blei:2006}
\@writefile{toc}{\contentsline {paragraph}{Topic trajectories.}{28}}
\@writefile{toc}{\contentsline {paragraph}{Influence values.}{28}}
\citation{blei:2003}
\@writefile{toc}{\contentsline {paragraph}{Topic proportions and topic assignments.}{29}}
\citation{bird:2008}
\citation{Radev:2009}
\citation{Thompson:2009}
\@writefile{toc}{\contentsline {section}{\numberline {3.3}Empirical study}{30}}
\newlabel{sec:data}{{3.3}{30}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.2}{\ignorespaces Spearman rank correlation between citation counts and posterior influence score, controlling for date (top) and fraction of citations explained by posterior influence (bottom).}}{31}}
\newlabel{fig:results}{{3.2}{31}}
\newlabel{sec:results}{{3.3}{31}}
\newlabel{eq:score}{{3.7}{31}}
\@writefile{toc}{\contentsline {paragraph}{Heuristic model.}{32}}
\@writefile{toc}{\contentsline {paragraph}{Shuffled corpus}{32}}
\citation{brown:1993}
\citation{brown:1993}
\citation{marcus:1993}
\citation{marcus:1993}
\citation{brown:1993}
\citation{toole:1984}
\citation{brown:1993}
\citation{toole:1984}
\citation{Nature.success:1969}
\@writefile{toc}{\contentsline {paragraph}{IBM Model 3}{33}}
\@writefile{toc}{\contentsline {paragraph}{The Penn Treebank}{33}}
\@writefile{toc}{\contentsline {paragraph}{Success in 1972}{33}}
\@writefile{lof}{\contentsline {figure}{\numberline {3.3}{\ignorespaces Most active words appearing in \cite  {brown:1993} (left) which have changed the most in a topic about translation. On right are words appearing in \cite  {toole:1984} in a topic about DNA and genetics. Terms are sorted by increase over 10 years.}}{34}}
\newlabel{fig:words}{{3.3}{34}}
\citation{NSF.website:2010}
\citation{toole:1984}
\citation{foo}
\citation{beim:2011}
\@writefile{toc}{\contentsline {paragraph}{Genetics in \emph  {Nature}}{35}}
\@writefile{toc}{\contentsline {section}{\numberline {3.4}New York Appellate Courts.}{35}}
\@writefile{toc}{\contentsline {paragraph}{The Cardozo Topic.}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {3.5}A parallel implementation of the model}{36}}
\newlabel{section:influence_parallel_inference}{{3.5}{36}}
\@writefile{toc}{\contentsline {section}{\numberline {3.6}A parallel implementation of the model}{38}}
\newlabel{section:influence_parallel_inference}{{3.6}{38}}
\citation{brown:1993}
\citation{toole:1984}
\citation{marcus:1993}
\citation{leskovec:2009}
\citation{alvarez:2009}
\citation{shaparenko:2007}
\citation{dietz:2007}
\@writefile{toc}{\contentsline {section}{\numberline {3.7}Conclusions and future work}{41}}
\citation{clinton:2004}
\citation{govtrack:2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Models of Spatial Voting and text}{42}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\citation{zimmer:2012}
\citation{deerwester:1990}
\citation{hofmann:1999}
\citation{blei:2003}
\citation{poole:1985}
\citation{poole:1991}
\citation{jackman:2001}
\citation{martin:2002}
\citation{clinton:2004}
\citation{blei:2003}
\citation{kogan:2009}
\citation{ramage:2009}
\citation{poole:1985}
\citation{poole:1991}
\citation{jackman:2001}
\citation{martin:2002}
\citation{clinton:2004}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}The Ideal Point Model}{43}}
\newlabel{sec:model}{{4.1}{43}}
\@writefile{toc}{\contentsline {paragraph}{Ideal points}{43}}
\citation{clinton:2004}
\citation{clinton:2004}
\citation{clinton:2004}
\@writefile{lof}{\contentsline {figure}{\numberline {4.1}{\ignorespaces Example one-dimensional ideal points from the 111th House of Representatives. Ideal points represent lawmakers' voting preferences. Democrats are blue and Republicans are red.}}{44}}
\newlabel{figure:example_ideal_points}{{4.1}{44}}
\newlabel{equation:trad_ipm}{{4.1}{44}}
\@writefile{toc}{\contentsline {section}{\numberline {4.2}A model for predicting votes with the text of new bills}{44}}
\citation{blei:2008}
\citation{Kogan:2009}
\citation{blei:2008}
\citation{blei:2003}
\@writefile{lof}{\contentsline {figure}{\numberline {4.2}{\ignorespaces The ideal point topic model. Priors over the multinomials $\theta _d$ and $\beta $ are both symmetric Dirichlet distributions.}}{46}}
\newlabel{fig:legis_gm}{{4.2}{46}}
\citation{jackman:2001}
\citation{clinton:2004}
\citation{martin:2002}
\citation{clinton:2004}
\citation{enelow:1984}
\citation{poole:1985}
\citation{heckman:1996}
\citation{jackman:2001}
\citation{martin:2002}
\citation{clinton:2004}
\citation{martin:2002}
\citation{wang:2010}
\citation{jackman:2001}
\citation{heckman:1996}
\newlabel{eq:posterior}{{4.2}{47}}
\citation{johnson:1999ch6}
\citation{quinn:2006}
\citation{thomas:2006}
\citation{pang:2008}
\citation{Salakhutdinov:2008a}
\citation{agarwal:2010}
\citation{wang:2010}
\citation{johnson:1999ch6}
\citation{jackman:2001}
\citation{martin:2002}
\citation{clinton:2004}
\citation{jordan:1999}
\citation{blei:2003}
\newlabel{sec:inference}{{4.2}{48}}
\citation{treetagger}
\newlabel{eq:var_post}{{4.3}{49}}
\newlabel{sec:experiments}{{4.2}{49}}
\newlabel{fig:log_likelihood}{{4.2}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.3}{\ignorespaces Vote log likelihood on heldout votes. Models are shown by color for different regularizations (x axis), for Congresses 106 to 111. For LARS and L2, the regularization is the complexity parameter; for the ITPM, the regularization is the the number of topics. The \emph  {yea} baseline is the horizontal black line. LARS is below the fold for 106-107. The ideal point topic model performs with less variance across its regularization parameter. }}{50}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.4}{\ignorespaces Topics can be visualized in the same latent political space as legislators and bills. This plot shows selected topics by coefficients $\bm  {\mathaccentV {hat}05E}\eta $, for a 64-topic model ($\bm  {\mathaccentV {hat}05E}\eta $s are normalized by mean and variance). Two topics (\emph  {people, month, recognize, ...} and \emph  {clause, motion, chair, ...}) with difficulty 4.68 and polarity 7.4 (respectively) are not shown.}}{51}}
\newlabel{fig:topics}{{4.4}{51}}
\citation{herszenhorn:2010}
\@writefile{toc}{\contentsline {section}{\numberline {4.3}Lawmakers' issue preferences in the U.S. Congress}{54}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.1}A model of exceptional voting patterns}{54}}
\newlabel{section:exceptional_model}{{4.3.1}{54}}
\@writefile{toc}{\contentsline {subsubsection}{Limitations of ideal point models.}{54}}
\citation{ramage:2009}
\citation{ramage:2009}
\@writefile{lof}{\contentsline {figure}{\numberline {4.5}{\ignorespaces In a traditional ideal point model, lawmakers' ideal points are static (top line of each figure). In the issue-adjusted ideal point model, lawmakers' ideal points change when they vote on certain issues, such as \emph  {Taxation} (top) and \emph  {Health} (bottom).}}{55}}
\newlabel{fig:moving_ideal_points}{{4.5}{55}}
\@writefile{toc}{\contentsline {subsubsection}{Issue-adjusted ideal points.}{55}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.6}{\ignorespaces Left: the issue-adjusted ideal point model, which models votes $v_{ud}$ from lawmakers and legislative items. Classic item response theory models votes $v$ using $x_u$ and $a_d, b_d$. For our work, documents' issue vectors $\bm  {\theta }$ were estimated fit with a topic model (left of dashed line) using bills' words $w$ and labeled topics $\beta $. Expected issue vectors $\mathbb  {E}_q\left [\bm  {\theta }| \bm  {w}\right ]$ are then treated as constants in the issue model (right of dashed line). Right: Top words from topics fit using labeled LDA \cite  {ramage:2009}. }}{56}}
\newlabel{figure:legis_gm}{{4.6}{56}}
\newlabel{table:example_topics}{{4.6}{56}}
\newlabel{equation:exploratory_ipm_old}{{4.4}{56}}
\citation{ramage:2009}
\citation{blei:2003}
\citation{ramage:2009}
\citation{crs:2011}
\citation{clinton:2004}
\citation{martin:2002}
\citation{poole:1985}
\citation{enelow:1984}
\citation{albert:1992}
\citation{heckman:1996}
\citation{jackman:2001}
\@writefile{toc}{\contentsline {subsubsection}{Using Labeled LDA to associate bills with issues.}{57}}
\newlabel{section:lda}{{4.3.1}{57}}
\@writefile{toc}{\contentsline {subsubsection}{Related Work.}{57}}
\citation{gerrish:2011}
\citation{wang:2010}
\citation{wang:2011}
\citation{agarwal:2010}
\citation{agarwal:2010}
\citation{wang:2011}
\citation{johnson:1999ch6}
\citation{jackman:2001}
\citation{martin:2002}
\citation{clinton:2004}
\citation{jordan:1999}
\citation{gerrish:2011}
\citation{robbins:1951}
\citation{bottou:2004}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.2}Inference for the adjusted ideal point model}{58}}
\newlabel{section:inference}{{4.3.2}{58}}
\newlabel{equation:variational_posterior}{{4.5}{58}}
\citation{govtrack:2009}
\newlabel{equation:approx_elbo_gradient}{{4.6}{59}}
\newlabel{section:empirical_analysis}{{4.3.2}{59}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.3}The United States Congress from 1999-2010}{59}}
\citation{jackman:2001}
\@writefile{lot}{\contentsline {table}{\numberline {4.1}{\ignorespaces Roll-call data sets used in the experiments. These counts include votes in both the House and Senate. Congress 107 had fewer fewer votes than the remaining congresses in part because this period included large shifts in party power, in addition to the attacks on September 11th, 2001.}}{60}}
\newlabel{table:data_stats}{{4.1}{60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.4}Vocabulary}{60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.5}Identification}{60}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.6}Traditional ideal points vs. issue-adjusted ideal points}{60}}
\newlabel{section:jackman_vs_exploratory}{{4.3.6}{60}}
\@writefile{toc}{\contentsline {subsubsection}{Examples: adjusting for issues.}{61}}
\@writefile{toc}{\contentsline {subsubsection}{A comparison of issue-adjusted ideal points $x_u$ and traditional ideal points.}{61}}
\@writefile{lot}{\contentsline {table}{\numberline {4.2}{\ignorespaces Issue-adjusted ideal points can explain votes better than standard ideal points. The x-axis of each small plot shows ideal point or issue-adjusted ideal point for a lawmaker. Each bill's indifference point $-\frac  {b_d}{a_d}$ is shown as a vertical line. Positive votes (orange) and negative votes (purple) are better-divided by issue-adjusted ideal points.}}{62}}
\newlabel{table:issue_adjustments}{{4.2}{62}}
\newlabel{figure:jackman_vs_offset}{{4.3.6}{63}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.7}{\ignorespaces Classic issue-adjusted ideal points $x_u$ (top row) separate lawmakers by party better than un-adjusted ideal points $x_u$ from the issue-adjusted model (bottom row). Republicans are colored red, and Democrats are blue. These ideal points were estimated in the 111th House of Representatives. The line connecting ideal points from each model has opacity proportional to the squared residuals in a linear model fit to predict issue-adjusted ideal points from ideal points. }}{63}}
\@writefile{toc}{\contentsline {subsubsection}{Evaluation of the predictive distribution.}{63}}
\newlabel{section:performance}{{4.3.6}{63}}
\@writefile{toc}{\contentsline {paragraph}{Sensitivity to $\lambda $.}{63}}
\@writefile{lot}{\contentsline {table}{\numberline {4.3}{\ignorespaces Average log-likelihood of heldout votes by regularization $\lambda $. Log-likelihood was averaged across folds using six-fold cross validation for Congress 109 (2005-2006). The variational distribution represented votes with higher heldout log-likelihood than traditional ideal points for $1 \le \lambda \le 10$. In a model fit with permuted issue labels (Perm. Issue), heldout likelihood of votes was worse than traditional ideal points for all regularizations $\lambda $. }}{64}}
\newlabel{table:lambda_comparison}{{4.3}{64}}
\@writefile{lot}{\contentsline {table}{\numberline {4.4}{\ignorespaces Average log-likelihood of heldout votes across all sessions for the House and Senate. Log-likelihood was averaged across folds using six-fold cross validation for Congresses 106 to 111 (1999-2010) with regularization $\lambda =1$. The variational distribution had higher heldout log-likelihood for all congresses in both chambers than either }}{64}}
\newlabel{table:session_comparison}{{4.4}{64}}
\@writefile{toc}{\contentsline {paragraph}{Performance across all sessions.}{64}}
\citation{cox:2002}
\citation{cox:2002}
\@writefile{toc}{\contentsline {paragraph}{Human labels vs. inferred text-based labels.}{65}}
\@writefile{toc}{\contentsline {paragraph}{Changes in bills' parameters.}{65}}
\@writefile{toc}{\contentsline {paragraph}{Sparsity of $\mathaccentV {tilde}07Ez_{uk}$.}{65}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.8}{\ignorespaces Procedural bills are more popular under the issue-adjusted voting model. Top: popularity $b_d$ of procedural bills under the issue-adjusted voting model is greater than with traditional ideal points. Bottom: consistent with \citet  {cox:2002} and \emph  {procedural cartel theory}, the polarity of procedural bills is generally more extreme than that of non-procedural bills. However, issue adjustments lead to increased polarity (i.e., certainty) among non-procedural votes as well. The procedural issues include \emph  {Congressional reporting requirements}, \emph  {Government operations and politics}, \emph  {House of Representatives}, \emph  {House rules and procedure}, \emph  {Legislative rules and procedure}, and \emph  {Congress}.}}{66}}
\newlabel{figure:bills_parameter_changes}{{4.8}{66}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3.7}Issues and Lawmakers}{66}}
\newlabel{section:lawmakers}{{4.3.7}{66}}
\newlabel{section:issues}{{4.3.7}{66}}
\@writefile{toc}{\contentsline {subsubsection}{Issues improved by issue adjustment.}{66}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.9}{\ignorespaces Log-likelihood increases when using adjusted ideal points most for procedural and strategic votes and less for issues frequently discussed during elections. $\unhbox \voidb@x \hbox {Imp}_k$ is shown on the x-axis, while issues are spread on the y-axis for display. The size of each issue $k$ is proportional to the logarithm of the weighted sum $\DOTSB \sum@ \slimits@ _{v_{ud}} \bm  {\theta }_{dk}$ of votes about the issue.}}{67}}
\newlabel{figure:issue_improvements}{{4.9}{67}}
\newlabel{equation:likelihood_improvement}{{4.8}{67}}
\@writefile{toc}{\contentsline {paragraph}{Issues associated with worse predictions.}{68}}
\@writefile{toc}{\contentsline {subsubsection}{Understanding legislators' voting amidst party bias.}{68}}
\newlabel{section:party_bias}{{4.3.7}{68}}
\newlabel{section:conditional_offets}{{4.3.7}{68}}
\@writefile{toc}{\contentsline {paragraph}{Controlling for ideal points.}{68}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.10}{\ignorespaces Histogram of issue adjustments for selected issues. Democrats are in the left column, and Republicans are in the right column. Both Democrats and Republicans tend to have small issue adjustments for traditional issues. Their issue adjustments differ substantially for procedural issues. A more-dispersed distribution of issue adjustments does not mean that these lawmakers tend to feel differently from one another about these issues. Instead, it means that lawmakers deviate from their ideal points more. }}{69}}
\newlabel{figure:issue_adjustment_distribution}{{4.10}{69}}
\citation{cox:1993}
\citation{cox:1993}
\@writefile{lof}{\contentsline {figure}{\numberline {4.11}{\ignorespaces Ideal points $x_u$ and issue-adjusted ideal points $x_u + z_{uk}$ from the 111th House for the substantive issue \emph  {Finance} and the procedural issue \emph  {Congressional Sessions}. Democrats are blue and Republicans are red. Votes about \emph  {Finance} and \emph  {Congressional Sessions} were better fit using issue-adjusted ideal points. For procedural votes such as \emph  {Congressional sessions}, lawmakers becoming more polarized by political party, behavior predicted by procedural cartel theory \citep  {cox:1993}. }}{70}}
\newlabel{figure:issue_improvements_ideals}{{4.11}{70}}
\@writefile{toc}{\contentsline {paragraph}{Finding exceptional issue-adjustments.}{70}}
\@writefile{lof}{\contentsline {figure}{\numberline {4.12}{\ignorespaces Significant issue adjustments for exceptional senators in Congress 111. Each illustrated issue is significant to $p < 0.05$ by a permutation test.}}{71}}
\newlabel{figure:significant_offsets}{{4.12}{71}}
\@writefile{toc}{\contentsline {paragraph}{Extreme lawmakers.}{71}}
\citation{fenno:1965}
\citation{jones:1964}
\citation{cox:1993}
\citation{cox:2002}
\citation{cox:1993}
\citation{cox:2005}
\citation{cox:2005}
\citation{cox:1993}
\citation{cox:2002}
\citation{cox:2005}
\citation{cox:2002}
\newlabel{section:procural_cartel_theory}{{4.3.7}{72}}
\@writefile{toc}{\contentsline {paragraph}{Procedural Cartels.}{72}}
\citation{martin:2002}
\citation{jackman:2001}
\citation{hoff:2002}
\citation{chang:2009}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}A time-series model of foreign affairs: sentiment between nation-states}{74}}
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces A time-series model of countries' interactions. Pseudo-observations of ``zero'' are added for regularization. Amazon Mechanical Turk labels are used to fit $\beta $, which is used to infer unobserved sentiments.}}{74}}
\newlabel{figure:gm}{{5.1}{74}}
\citation{kogan:2009}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Foreign relations and their influence on news reporting}{75}}
\newlabel{section:model}{{5.1}{75}}
\@writefile{toc}{\contentsline {paragraph}{A temporal model of interaction.}{75}}
\newlabel{equation:sentiment}{{5.2}{75}}
\newlabel{section:text_regression}{{5.1}{75}}
\citation{gartzke:1998}
\citation{hoff:2002}
\citation{sarkar:2005}
\citation{chang:2009}
\citation{kogan:2009}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Related work}{76}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Inference}{76}}
\@writefile{toc}{\contentsline {paragraph}{M Step.}{76}}
\@writefile{toc}{\contentsline {paragraph}{E Step.}{76}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Estimation of sentiment $s$}{77}}
\newlabel{section:sentiment_models}{{5.3}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {5.4}A latent-space model of foreign relations}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.1}Posterior inference}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.2}Supervised sentiment analysis}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4.3}Unsupervised sentiment analysis}{77}}
\@writefile{toc}{\contentsline {section}{\numberline {5.5}Empirical studies: comparisons with ground truth}{77}}
\newlabel{section:experiments}{{5.5}{77}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5.1}Datasets and tokenization}{77}}
